{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agent_framework import AgentRunResponse,ChatAgent,HostedFileSearchTool,HostedVectorStoreContent\n",
    "from agent_framework.azure import AzureAIAgentClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3bcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_vector_store(client: AzureAIAgentClient) -> tuple[str, HostedVectorStoreContent]:\n",
    "    \"\"\"Create a vector store with sample documents.\"\"\"\n",
    "    file_path = '../files/demo.md'\n",
    "    file = await client.project_client.agents.files.upload_and_poll(file_path=file_path, purpose=\"assistants\")\n",
    "    print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "\n",
    "    vector_store = await client.project_client.agents.vector_stores.create_and_poll(file_ids=[file.id], name=\"graph_knowledge_base\")\n",
    "\n",
    "    print(f\"Created vector store, ID: {vector_store.id}\")\n",
    "\n",
    "\n",
    "    return file.id, HostedVectorStoreContent(vector_store_id=vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-LsKCPDUXQL3uYr3s8jhAK6\n",
      "Created vector store, ID: vs_78OP3E7BCBuey0g9UpLiG3q2\n",
      "Agent created. You can now ask questions about the uploaded document.\n",
      "GraphRAG is an AI-based content interpretation and search capability that leverages large language models (LLMs) to parse data into a knowledge graph. It enables answering user questions about a user-provided private dataset by connecting information across large volumes of data. This connection capability allows GraphRAG to address questions that are difficult or impossible to answer with traditional keyword or vector-based search. It can answer complex questions that span many documents and also thematic questions like identifying top themes in a dataset.\n",
      "\n",
      "The system is intended for critical information discovery and analysis use cases where relevant information spans multiple documents and may be noisy or intermixed with misinformation. It is designed to be used by trained users who apply responsible analytic approaches and critical reasoning. GraphRAG provides high insight but requires human domain expert verification and augmentation of the answers generated.\n",
      "\n",
      "Operationally, GraphRAG is best used on domain-specific text corpora rich in identifiable entities (people, places, things). It depends on well-constructed indexing, which can be expensive, so testing indexing on small datasets first is recommended. Although it is designed to be robust against prompt and data injection attacks and to have low hallucination rates, the underlying LLM configured with GraphRAG may still generate inappropriate content, so safety measures should be applied as appropriate.\n",
      "\n",
      "Evaluation of GraphRAG includes assessing accurate representation of datasets, transparency and groundedness of responses, resilience to injection attacks, and hallucination rates through both manual and automated methods.\n",
      "\n",
      "In summary, GraphRAG builds a knowledge graph from user data using LLMs to enable sophisticated, cross-document question answering and thematic analysis, intended for responsible use by knowledgeable users with human review of results recommended for reliability and safety.\n",
      "\n",
      "For more detailed information, see the excerpt from the uploaded document \"demo.md\"【4:0†demo.md】【4:1†demo.md】."
     ]
    }
   ],
   "source": [
    "async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        file_id, vector_store = await create_vector_store(chat_client)\n",
    "\n",
    "        file_search = HostedFileSearchTool(inputs=vector_store)\n",
    "        \n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"PythonRAGDemo\",\n",
    "            instructions=\"\"\"You are an AI assistant that helps people find information in a set of documents. Use the File Search tool to look up relevant information from the files when needed to answer user questions. If you don't know the answer, just say you don't know. Do not make up answers.\n",
    "                \"\"\",\n",
    "            tools=[file_search],  # Tools available to the agent\n",
    "            tool_choice = \"auto\",  # Let the agent decide when to use tools\n",
    "        )\n",
    "                \n",
    "\n",
    "        print(\"Agent created. You can now ask questions about the uploaded document.\")\n",
    "\n",
    "        query = \"What's GraphRAG?\"\n",
    "        async for chunk in agent.run_stream(query, tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.vector_store_id]}}):\n",
    "                \n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
