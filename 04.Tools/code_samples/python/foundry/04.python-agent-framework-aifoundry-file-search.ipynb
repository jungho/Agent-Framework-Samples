{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97f08567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agent_framework import AgentRunResponse,ChatAgent,HostedFileSearchTool,HostedVectorStoreContent\n",
    "from agent_framework.azure import AzureAIAgentClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a3bcf9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d3ca050",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_vector_store(client: AzureAIAgentClient) -> tuple[str, HostedVectorStoreContent]:\n",
    "    \"\"\"Create a vector store with sample documents.\"\"\"\n",
    "    file_path = '../../files/demo.md'\n",
    "    file = await client.project_client.agents.files.upload_and_poll(file_path=file_path, purpose=\"assistants\")\n",
    "    print(f\"Uploaded file, file ID: {file.id}\")\n",
    "\n",
    "\n",
    "    vector_store = await client.project_client.agents.vector_stores.create_and_poll(file_ids=[file.id], name=\"graph_knowledge_base\")\n",
    "\n",
    "    print(f\"Created vector store, ID: {vector_store.id}\")\n",
    "\n",
    "\n",
    "    return file.id, HostedVectorStoreContent(vector_store_id=vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aef5316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded file, file ID: assistant-VmANqc1CMnLJsAEh2qatnc\n",
      "Created vector store, ID: vs_uAsA1TJlNbYWjnYYjxO09rvn\n",
      "Agent created. You can now ask questions about the uploaded document.\n",
      "GraphRAG is an AI-based content interpretation and search system that uses large language models (LLMs) to parse data and create a knowledge graph for answering user questions about a provided private dataset. It excels at connecting information across large volumes of data to answer complex questions that span many documents or address thematic aspects, which are difficult for typical keyword or vector-based search systems to handle.\n",
      "\n",
      "GraphRAG is designed to support critical information discovery and analysis use cases involving noisy data, misinformation, or abstract questions. It is meant for users trained in responsible analytic approaches who can apply domain expertise to verify and augment the answers produced. It works with domain-specific text corpora and does not collect user data itself.\n",
      "\n",
      "The system has been evaluated for accurate data representation, transparency and groundedness of responses, resistance to prompt and data injection attacks, and low hallucination rates. Its main limitations include dependence on effective indexing of domain-specific concepts, which can be resource-intensive, and the need for human expert review of outputs. It is best applied to entity-rich text data focused on a common topic or theme.\n",
      "\n",
      "Overall, GraphRAG facilitates insightful and responsible analysis by linking information within complex datasets, but it requires careful operational use and human oversight to ensure reliability and appropriateness of outputs.\n",
      "\n",
      "This summary is based on detailed information found in the GraphRAG responsible AI FAQ document【4:0†demo.md】【4:1†demo.md】."
     ]
    }
   ],
   "source": [
    "async with (\n",
    "        AzureCliCredential() as credential,\n",
    "        AzureAIAgentClient(async_credential=credential) as chat_client,\n",
    "    ):\n",
    "        file_id, vector_store = await create_vector_store(chat_client)\n",
    "\n",
    "        file_search = HostedFileSearchTool(inputs=vector_store)\n",
    "        \n",
    "        agent = chat_client.create_agent(\n",
    "            name=\"PythonRAGDemo\",\n",
    "            instructions=\"\"\"You are an AI assistant that helps people find information in a set of documents. Use the File Search tool to look up relevant information from the files when needed to answer user questions. If you don't know the answer, just say you don't know. Do not make up answers.\n",
    "                \"\"\",\n",
    "            tools=[file_search],  # Tools available to the agent\n",
    "            tool_choice = \"auto\",  # Let the agent decide when to use tools\n",
    "        )\n",
    "                \n",
    "\n",
    "        print(\"Agent created. You can now ask questions about the uploaded document.\")\n",
    "\n",
    "        query = \"What's GraphRAG?\"\n",
    "        async for chunk in agent.run_stream(query, tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.vector_store_id]}}):\n",
    "                \n",
    "            if chunk.text:\n",
    "                print(chunk.text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03956e01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  },
  "polyglot_notebook": {
   "kernelInfo": {
    "defaultKernelName": "csharp",
    "items": [
     {
      "aliases": [],
      "name": "csharp"
     }
    ]
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
